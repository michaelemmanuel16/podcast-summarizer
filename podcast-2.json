{"podcast_details": {"podcast_title": "Humans vs. Machines with Gary Marcus", "episode_title": "AI Took My Career!", "episode_image": "https://megaphone.imgix.net/podcasts/3514e09e-f852-11ea-ad6e-af97478985e9/image/image001.jpg?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Hackers and cybercriminals have always held this kind of special fascination. Obviously, I can't tell you too much about what I do. It's a game. Who's the best hacker? And I was like, well, this is child's play. I'm Dina Temple-Reston, and on the Click Here podcast, you'll meet them and the people trying to stop them. We're not afraid of the attack. We're afraid of the creativity and the intelligence of the human being behind it. Click Here, stories about the people making and breaking our digital world. AI machines, satellite, and ignition. Click Here and lift off. Every Tuesday, wherever you get your podcasts. Now automation provides machines that do the brain work. But what does this mechanical brain plus a mechanical muscle do to people, to jobs, to the way we live? Artificial intelligence could replace millions of jobs. Altogether, in 15 years, that's going to displace about 40% of jobs in the world. What does that do to the fabric of society? When it comes to jobs, the conflict between humans and machines goes back centuries. New technologies, the factory, personal computers, the internet, profoundly change how we live and work. AI could lead to the most significant changes of all. Already this year, IBM announced that it intends to lay off 30% of its back office staff over the next five years, nearly 8,000 jobs. IBM was a pioneer in developing AI. Now artificial intelligence may take many IBM jobs away. Then there are the Hollywood screenwriters who went on strike this spring. Worrying, maybe with good reason, that the studios want to replace them with AI. Google has developed an AI program called Genesis that can write news and has pitched the technology to the New York Times, Washington Post, and the Wall Street Journal. Whose jobs will AI come for next? Will AI work for us or will we work for AI? I'm Gary Marcus and this is Humans vs. Machines. When I first started painting, I wasn't thinking about AI. I wasn't thinking about it as a career either. I just thought about the next painting, the next painting, the next painting. This is Amy Winter, a young art school graduate living and working as a concept artist in Vancouver, British Columbia. She has spent years working on what she loves, trying to carve out a career as an artist. Now she wonders whether AI will make all that work irrelevant. Tell us what concept work means. So what is the kind of art that you do and like to do? How I usually describe it to the layperson is what an architect is for buildings. A concept artist is for anything visual in games or animation, television, movies. If it exists on screen, it usually needed to be designed in some way. You need plans and that's where the concept artist comes in. For example, one of my assignments was to mash up a gorilla, a hedgehog, and a pig into one creature. So you have to make your own chimera kind of. Yeah, yeah. And within that, there's a lot of creativity involved too, but you're not in charge of anything as a concept artist. The director's in charge of things, the creative director, the art director, the producers. All of those people get final say. And the beauty of being a concept artist for me is that it's not just on you. It's almost like a service job in art. Like you're a cook in a kitchen. But things are starting to change in the commercial art world. The emergence of AI art generators means that people with no artistic training at all can create impressive images just by describing them. That trend started in 2015 when Google released Deep Dream, an AI generator that took images and turned them into psychedelic renderings. And so that was kind of first hint of this thing that was on the horizon. And it was kind of interesting. And some artists were using it for various purposes. And then fast forward to last summer, summer 2022. And very quickly, I have friends coming to me being, oh, look what I made with Mid Journey. Oh, look what I made with Mid Journey. And I, well, what's Mid Journey? Mid Journey is an AI program that can translate text into high quality images, one of which was so good it took first place in the competition. And they're showing me these images and I'm thinking, oh, shit, like I just started school. I paid them a lot of money. They're coming to me with this, oh, look what I can do. And it made me very, very nervous very, very quickly. I was putting it anywhere from like 50 to 70 hours a week over and over and over. And you're putting in all this work and then you know at some point it's going to end and you're going to have to try to find work in this industry. And then on top of that, you have this technology that has come out of nowhere and you don't know how the industry is going to respond to it by the time you graduate. And so that added pressure just made me feel like I don't know what I'm doing right now. So I guess you must talk about this a lot to your fellow artists. What are people saying? What's the range of opinion? I have friends or former classmates who just don't care. They're just like, I'm just not worrying about it. I'm just going to keep my head down. But on the other end of the spectrum, there are people who are very worried. You're hearing a lot of anecdotal stories of a colleague of a colleague losing their job because of this. Of studios not hiring more artists that they would have because of AI or downsizing certain departments. And I don't know how much of it personally is true. And that adds to the kind of fear because there's already a lot of uncertainty. And this feels kind of historically unprecedented. This level of technology so quickly with so much mass adoption, the perfect storm. It's an amazing storm. There's no question about that. Yeah. That feeling that Amy is talking about, the anxiety that AI is going to change or take her job. Lots of other people are feeling it too. Here's Brian Merchant, who covers tech at the LA Times. I have illustrator friends and I've interviewed other folks who say some creative directors have explicitly told them we are using mid-journey now. So it is at the very least starting to erode the volume of work that freelancers got. There's another issue. These programs are trained on millions of illustrations, including some by the very artists who could lose their jobs. Their own work is being used to train the systems that could replace them. For a while, a lot of artists were experimenting and trying to get Dolly or mid-journey or stable diffusion to sort of do art in their styles. And a lot of these artists also take that issue of consent very seriously for, I think, justifiable reasons. That their work was vacuumed up into these data sets. They had no say over it. They believe that that's a violation, especially when it's turned around and used for profit. So I think that they're, from a moral perspective, that's their argument is that if you don't want to see all this work to go away, we have to fight now. In the spring of 2023, the Center for Artistic Inquiry and Reporting and the artist Molly Crabapple published an open letter calling on publications to restrict the use of AI in illustration. Over 3,000 people in the industry have signed. Brian's been thinking about this a lot, thinking about something that happened over 200 years ago at the beginning of the Industrial Revolution, when a group of workers in England known as the Luddites became famous for smashing machinery. Since then, being called a Luddite generally means you're anti-progress, afraid of change. But the story of the Luddites is more complicated than that. They weren't just vandals. The Luddites and the proto-Luddites were cloth workers. And the cloth workers were a huge sort of industrial workforce, a big base, just hundreds of thousands of people, the biggest in England, in fact. And they would, of course, come to drive the Industrial Revolution as we know it. So when the machines started being used by entrepreneurs who noticed they could get some real labor savings out of this, that's when you started to see some real tensions. And the entrepreneurs, if you kind of imagine Uber coming into a city and saying, oh, we're going to ignore the taxi code because we're a software company, we're not going to follow the rules the taxi drivers have to do. We're just going to play by our own rules. That's pretty analogous to what a lot of the entrepreneurs who adopted this machinery did. And that's part of what caused a lot of the grievances. The new factories and new technology didn't just threaten workers' wages. They threatened a way of life. It looked like before my life was I got to wake up with my wife and kids. We had breakfast and then we maybe took a walk in the garden and we went upstairs to the loom. We'd all sing songs together. I could decide whether or not to work that day. To, nope, you are going into the windowless room where machines are clattering, where you're inhaling fibers from cotton and an overseer all day long is telling you what to do, when you can leave, what you have to work on, when you can take a break and all that. It was really appalling to a lot of people. And so they argued that that was unfair to the human workers. And they asked Parliament to sort of uphold that. Parliament turns it over, says, no, no support's forthcoming. So what happens with the Luddites is as they're smashing more machines, getting more popular, they're compared to Robin Hood very intentionally. They're super popular among the working classes. The state moves in to intervene and they say, we're going to make breaking a machine, if you break a frame, it will be a capital crime and we're going to make it punishable by death. Wow. Are there any public intellectuals at this point saying it's terrible? These people are losing their jobs or is it just the protesters and nobody else cares about them? Yeah, they have some very famous public intellectuals come to their defense and Lord Byron, who is about to become not just the most famous poet, but maybe the most famous person in the world besides Napoleon at the time, a true celebrity. He uses his very first speech in the House of Lords in defense of the Luddites. It's a really remarkable speech. It's a full throated wild defense and so much so that it's almost ineffectual politically speaking. So that law goes into effect anyways. But for the rest of his life, Byron will circle back and defend the Luddites. What they were fighting for was working dignity, fighting for agency over their lives, fighting against the rise of the factory and being forced into a system that then really looked like subjugation. 200 plus years ago, the Luddites fought to have a say in how much machines would change their lives. Today's conversations are echoing that past. In May 2023, the Writers Guild went on strike. It's first since 2007 after negotiations with the Alliance of Motion Picture and Television Producers broke down. Nobody would say that Hollywood screenwriters faced a grim life of factory work like the Luddites, but writers are also in a fight for their livelihood. AI wasn't even at the top of that list. If anything, they were more concerned about how streaming platforms have been used to lower their rates. But they did put into the contract this very straightforward stipulation that was no chat GPT or AI service will be used to produce an original script. Well, the studios said, no, how about instead we meet every year and we talk about technology? That sent a red flag up and they said, wait a minute. And they realized that that what they were more likely planning on doing was to maybe have chat GPT generate a first draft and then hiring someone to do a rewrite. And the thing is, you don't have to pay writers as much for rewrites. It's just far less well compensated and it's a way to sort of break down the writers earnings, break down how much you have to pay and break down the power that writers have. So it became this flash point and the writers, I think, justifiably said, well, we're not going to give on this. We're not going to let that happen. So then it became part of the face off that you've probably seen in headlines. And it echoes beyond the writer's strike. Lawyers are worried that GPT will start to write their legal briefs. News organizations are hoping large language models will help with research and writing. Wendy's is experimenting with a chat bot that can take orders at its drive throughs. Will we all be standing in the unemployment line soon? Not necessarily, says Eric Bringelston, an economist who has studied the effects of technology on the workforce for years, first at MIT and now at Stanford. He calls himself a techno optimist. I was very surprised, as a lot of people were with large language models recently and generative AI and their ability to solve a lot of problems that I didn't expect to be solvable. Dr. Bringelston looks at AI through the lens of the last major technological disruption, the digital revolution, how it affected the labor force and who ended up being the winners and losers last time around. Computers were complementing and helping college educated workers, allowing them to be more productive and create more value and get higher pay. But it was replacing a lot of low skill workers and especially middle skill kind of clerical work, accounting, a lot of middle managers. There were changes in tax policy, but most economists, including us, found technology, especially computer technology, to be the single biggest factor in that shift in the income distribution. Dr. Bringelston was involved in one of the first, if not the first, studies on how generative AI could transform a business with Daniel Lee and Lindsay Raymond. I asked him to walk us through. We were really excited to do this paper. We started a few years ago and we didn't totally realize how hot generative AI would be by the time we finished it. But Lindsay is a PhD student at MIT and we helped her up with a company that was using generative AI to help call center operators. So instead of having the AI directly answer questions for customers, they had the AI kind of look over the shoulder of the call center operators and give them hints and suggestions about what they could say to be more effective. And they had millions, literally millions of transcripts that they could use as training data, some of which turned out effective, that made the customers happy and solve their problems. Some of them were not so effective. And what we found was several things. First off, we found that overall is a significant productivity boost, about 14% overall, but interestingly over 30% for the least experienced workers. They got the biggest gain. The most experienced workers got almost no gain. And if you think about it, it shouldn't be surprising because the data was learned from the most experienced workers and it basically took that tacit knowledge and coached the less experienced workers. And after using it for a couple of months, they performed very much like the most experienced workers. It's worth pausing here to consider what happened. The least experienced workers gained the most in the study. The most experienced workers, who in a sense helped train the AI system, didn't gain much. We found that managers didn't have to spend as much time coaching and they had a broader span of control. And the overall result was not only higher productivity, but customer sentiment went way up. We could look at the words used and there were fewer angry words and more happy words by customers after they implemented the system. And turnover among the call center agents went down, so they were more likely to stick around. I guess they liked it better when customers were happy than when customers were yelling at them. So this all sounds great. It does raise a question though. If the productivity is 14% higher, does that mean we're going to lose one, seven jobs there because they're not needed anymore and you can do it with fewer people? That is a great question and it's most people's intuition. It is not the best way to think about it. And very often when something gets cheaper or gets more productive, then output expands and so you end up having the same or sometimes even more employment. Let me give you an example. So when jet engines were introduced, pilots became dramatically more productive. They could do more passenger miles per hour. But the result was not that we needed fewer pilots. The result was that people flew a lot more. So it really depends very much on the demand elasticity, to use the economic term. As Dr. Brignolfsen explains, sometimes productivity leads to less employment. Sometimes it leads to more. But more employment doesn't necessarily mean better employment. One of the big questions about AI is this. Will it take jobs from workers or help them perform better? Replacement or augmentation? One thing I think a lot about is safety and cost of error. So for some tasks where the cost of error isn't that high, large language models are great. But like medical advice where the cost of error might be high, they might be problematic. Well, it goes both ways, doesn't it? In some cases, technology is going to augment people, make them more productive, and we'll see more of that work being done. We'll see more income and it'll actually be a great thing for them. In other cases, the tasks will be automated and eliminated. And in almost all cases, it'll be rearranged. I mean, I think that having a large language model as a second opinion might be very valuable for a human doctor who sometimes overlooks some situation or case that the AI could remind them of. Humans and machines sometimes make different kinds of errors. So when you put them in combination, they're less likely to overlook things that either one of them might miss. Of course, it's not always a bed of roses. The Wall Street Journal recently looked at some hospitals that were using AI programs to detect sepsis. The programs were designed to help nurses determine who might be at risk. What happened, though, is that the nurses felt tremendous pressure to accept the AI judgment, whether they agreed with it or not. After all, these AI systems cost a lot of money. Instead of working with the programs, the nurses were essentially working for them. Dr. Brignolson argues that there are broader social and economic reasons for keeping people in the loop. AI in the workplace could affect not just individual jobs, but overall economic inequality. Technology sometimes boosts inequality. Sometimes it reduces inequality. There's not any iron law that ever does one or the other. I think there's good reason to believe that it's going to reduce it once again. There was a terrific paper by my former grad student, now Wharton professor Daniel Rock, and a team of others at OpenAI that looked at the types of tasks that GPT was most likely to affect. And interestingly, it was a lot of higher wage professional type tasks, and the lower paid jobs like a plumber or carpenter were less likely to be affected. So it was the opposite of what we saw in the previous decade. And affected doesn't mean replaced, but there's certainly cause to believe that the net effect will be to reduce income inequality. And we saw the same thing in a very concrete case in that call center analysis I looked at, where the less skilled workers actually had a benefit compared to the more skilled workers. So I think you've thought about tax policy a bunch. We talked about it once or twice over the years as a way of dealing with dynamics that might change in employment markets. You want to talk about that a little bit? Sure. Instead of what we do now, which is we tax labor much more than capital, we do it the other way around. We at least have it even or perhaps tax capital more than labor. The current tax system has about half the marginal tax rate on capital income as labor income. And that means that if you have an idea that we'll have a thousand robots working, you get taxed less than if you have an idea with a thousand humans working. Instead, let's have them even or tax that capital more. And then every time an entrepreneur starts a business or a technologist comes up with a new idea, they get a little bit of a reward for steering technology in the direction of keeping humans in the loop. So I want to make sure we understand we have a lot of agency in the direction, not complete, but we have a lot of agency in directing it. And we can choose to direct the technology in ways that are likely to create more widely shared prosperity or we can abdicate and leave it to be more concentration of wealth and power and leaving a lot of people behind. Brian Merchant from the LA Times isn't as optimistic. Inevitably, it's going to be the people at the bottom of the ladder with the fewest protections who are doing the least quote unquote skilled work. I would argue that there's no such thing really as unskilled work, but the work that gets classified that way and thus gets opened up in the eyes of management to replacement. I think there are a lot of workers that are vulnerable right now. And I just want to emphasize that it's not particularly useful to worry about strict job replacement. It's going to happen sometimes, but more frequently, it's going to be piecemeal and it's going to be in fits and starts. And the biggest workers that stand to be impacted are the workers that stand to be impacted by just about everything else. The workers that have the least amount of power that rely either on informal gig work or freelance contracts that can be made to compete with sort of the text or image generation. AI is almost sure to change how we work. I also wonder how AI might change the quality of the work, particularly creative work. How is AI going to change art itself? I put this question to Amy. What worried me the most wasn't so much the capability of what these programs could do. It was seeing the talk around how people received it because the first big headline that I remember seeing was the one about someone who won an art competition, a digital art competition using, I think he was using mid journey. But I remember looking at this thinking like, okay, yeah, there are parts of this that look like a beautiful Renaissance painting, but other parts of this that are have such basic errors. From an art standpoint, from a technical standpoint, this has become the normal for a lot of these AI generated images where you have this combination of high levels of artistic rendering with elementary basic mistakes that a human artist would never make. What are some of the kinds of errors that these systems made? There's a lot of them, most notably, and almost anyone listening to this podcast would have heard about the problem with hands. A lot has been written about, oh, well, these AI image generators don't do human hands very well, which is to say most of the time they really mess it up. And they've been making improvements to this. But the same reasons that these AIs are bad at hands, they're also bad at a number of other things because the way they work isn't the way human beings create these images. Because as humans, we're able to recognize that, you know, if you see part of a bike behind a sign, you can extrapolate the other parts of the bike behind the sign and you can carry it through and a trained artist can draw through that. But the AI doesn't really understand that. Of course, it's almost certain that these programs will get better. There will be AI models that can render better hands and create better music. Does that mean AI will ever produce truly innovative work like a Frida Kahlo, Thelonious Monk, Margaret Atwood? Probably not. But for the everyday creative work we see, news reports, illustrations, pop songs, animation, maybe AI will be able to do something 80% as well for a fraction of the cost. And at that point, both employers and society may have some important choices to make. AI is not going to take your job, the boss is. So it's always a choice. And if you have a union or if you're organized or if you have collective action, you're far more likely to be able to sort of negotiate that outcome than otherwise. There's going to be a lot of interesting uses and useful use cases for AI. But we want to be in a position where people can negotiate those uses so they're not just steamrolled by them. So I don't think it's out of the question that we could reach a combustible moment. People's identities are bound up in their in their livelihoods and their work and how they how they work and how they spend their days. You've spent 30 years in a trade and all of a sudden you can't do it anymore. That's going to make you angry. And I don't think the fact that the GDP may ultimately be unaffected is going to be much solace. And I don't want to leave the segment without also saying much of it is a choice that these effects are not exogenous or God given or decided by some force of technology. We have tremendous ability to direct technical change, tax policy, managerial decisions, worker decisions, training, education. There are so many things that can direct technology in different ways and that we can steer the technology more than we sometimes realize. And we can choose to have more widely shared prosperity or more concentration of wealth. And we shouldn't just sit back and say, well, it is what it is. On the next episode of Humans vs. Machines, we talk about AI and human relationships. What does it mean to connect with an AI? It's hard to to stay skeptical when someone is really telling you like that this brings me such a joy and love in my life when I haven't experienced that in other parts. If it turned out that AI could ease the pain of loneliness, there'd be a huge wound to humanity. What social role these systems are going to have, whether they're going to be property, whether they're going to be companions, whether they're going to be companions that can be property. Like, there's a lot of ethical issues. I'm your host, Gary Marcus, and that's next week on Humans vs. Machines. Humans vs. Machines is brought to you by Aventine, a nonprofit research institute creating and sharing work that explores how today's decisions could affect the future. The views expressed don't necessarily reflect those of Aventine, its employees or affiliates. For a transcript of the episode and more resources related to what you've heard in today's episode, please visit Aventine.org slash podcast. Danielle Mattoon is the editorial director of Aventine. Humans vs. Machines was created by Aventine and Gary Marcus and written by Gary Marcus and Bruce Hedlum. It is produced in partnership with Pineapple Street Studios. Our associate producers are Lisa Cerda, Emerald O'Brien, and Maria Robin Somerville. Our lead producer is Alexis Moore with production assistance from Stephen Key and Eric Menel. Our managing producer is Camila Cacciani. Pat St. Clair and Joel Lovell are our editors. Our engineers are Davy Sumner and Jason Richards. Legal services for Pineapple Street by Bianca Grimshaw at Granderson de Rocher and fact checking by Will Tavlin. Original music by Benton Rourke with additional music from Epidemic Sound and Blue Dot Sessions. Our executive producers are J.N. Barrie and Max Linsky. And thanks as ever to Athena. I'm your host, Gary Marcus. You can follow me on Twitter at Gary Marcus and Substack at GaryMarcus.Substack.com. You can find Aventine at Aventine.org and at Aventine underscore INST on Instagram and Twitter. Make sure to listen to us on the Odyssey app or wherever you get your podcasts."}, "podcast_summary": "In this podcast, \"Humans vs. Machines,\" the impact of AI on jobs and creative work is discussed. The emergence of AI art generators and language models like Mid-Journey and GPT has raised concerns about job displacement in industries such as commercial art and writing. While AI can enhance productivity and performance, there are fears that it could lead to the replacement of human workers in certain roles. However, economists argue that technology can also create more employment opportunities and reduce income inequality. It is suggested that tax policies should be reevaluated to incentivize keeping humans in the loop and to create a more widely shared prosperity. Ultimately, the direction of technological change and its impact on society will require collective action and decision-making.", "podcast_guest": {"name": "Elon Musk", "org": "Tesla", "title": "", "summary": "Not Available"}, "podcast_highlights": "- Highlight 1: \"AI could replace millions of jobs. Altogether, in 15 years, that's going to displace about 40% of jobs in the world.\"\n- Highlight 2: \"It was seeing the talk around how people received it because the first big headline that I remember seeing was the one about someone who won an art competition, a digital art competition using, I think he was using mid-journey.\"\n- Highlight 3: \"Technology sometimes boosts inequality. Sometimes it reduces inequality. There's not any iron law that ever does one or the other.\""}